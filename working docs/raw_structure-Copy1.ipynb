{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nytårstalen 2477\n"
     ]
    }
   ],
   "source": [
    "def nameFile(stri):\n",
    "    char_count = 0\n",
    "    year = \"\"\n",
    "    counter = -1\n",
    "\n",
    "    for character in stri:\n",
    "        counter += 1\n",
    "\n",
    "        if  counter+3 == len(stri):\n",
    "            break\n",
    "        if stri[counter].isdigit() and stri[counter+1].isdigit() and stri[counter+2].isdigit() and stri[counter+3].isdigit():\n",
    "            year = stri[counter]+stri[counter+1]+stri[counter+2]+stri[counter+3]\n",
    "        if len(year) == 4:\n",
    "            return \"Nytårstalen \"+year\n",
    "\n",
    "    return \"Nytårstalen (årstal mangler)\"\n",
    "\n",
    "print(nameFile(\"2477\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk (just once)\n",
    "import nltk #natural language toolkit\n",
    "import re #regular expressions\n",
    "import string #stringfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.corpus.stopwords.words('danish')\n",
    "sw_dk = nltk.corpus.stopwords.words('danish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a816724b0038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msw_dk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bare'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msw_dk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'får'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcustom_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#sw_dk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "sw_dk.append('år')\n",
    "sw_dk.append('må')\n",
    "sw_dk.append('kan')\n",
    "sw_dk.append('så')\n",
    "sw_dk.append('ved')\n",
    "sw_dk.append('går')\n",
    "sw_dk.append('hele')\n",
    "sw_dk.append('både')\n",
    "sw_dk.append('bare')\n",
    "sw_dk.append('får')\n",
    "custom_stopwords()\n",
    "\n",
    "#sw_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_speech(file):\n",
    "    with open(file) as file_object:\n",
    "        content = file_object.read()\n",
    "\n",
    "    return content\n",
    "\n",
    "#speech = open_speech(\"test_data/speech.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_speech(txt):\n",
    "    txt = txt.lower() #sætter alle karaktere til lower case\n",
    "    txt = re.sub('\\n','', txt) #fjerner alle \\n \n",
    "    txt = re.sub('\\[.*?]','',txt) #fjerner [] og indholdet\n",
    "    txt = re.sub('\\([^)]*\\)','',txt) #fjerner () og indholdet\n",
    "    txt = re.sub('\\d', '', txt) #fjerner tal(digits)\n",
    "    txt = re.sub('[%s]' % re.escape(string.punctuation), '', txt) #fjerner tegn\n",
    "\n",
    "    return txt\n",
    "\n",
    "#speech = clean_speech(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_years():\n",
    "    now = datetime.datetime.now()\n",
    "    result = []\n",
    "    year = 2001\n",
    "    \n",
    "    while year < now.year:\n",
    "        \n",
    "        result.append(year)\n",
    "        year += 1\n",
    "    \n",
    "    return result\n",
    "print(get_years())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(years):\n",
    "    data = {}\n",
    "    file = \"\"\n",
    "    \n",
    "    for i, year in enumerate(years):\n",
    "        file = 'test_data/Nytårstalen '+str(year)\n",
    "        data[str(year)] = clean_speech(open_speech(file))\n",
    "        \n",
    "    return data\n",
    "\n",
    "data_dict = create_data(get_years())\n",
    "#data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ændrer dict value fra string til list\n",
    "def value_to_list(value):\n",
    "    value_list = ''.join(value)\n",
    "    \n",
    "    return value_list\n",
    "\n",
    "data_combined = {key: [value_to_list(value)] for (key, value) in data_dict.items()}\n",
    "#data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def data_dict_to_df():\n",
    "    df_data = pd.DataFrame.from_dict(data_combined).transpose()\n",
    "    df_data.columns = ['speech']\n",
    "    \n",
    "    return df_data\n",
    "df_data = data_dict_to_df()\n",
    "#df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv_dk = CountVectorizer(stop_words=sw_dk) \n",
    "data_cv = cv_dk.fit_transform(df_data.speech)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv_dk.get_feature_names())\n",
    "data_dtm.index = df_data.index\n",
    "data_dtmi = data_dtm.transpose()\n",
    "#data_dtmi\n",
    "#data_dtm[\"2001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_all(amount):\n",
    "    top_dict = {}\n",
    "    data = data_dtm.transpose()\n",
    "    for year in data.columns:\n",
    "        top = data[year].sort_values(ascending=False).head(amount)\n",
    "        top_dict[year] = list(zip(top.index, top.values))\n",
    "\n",
    "    return top_dict\n",
    "\n",
    "#top_words_all(4)\n",
    "top_words = top_words_all(10)\n",
    "#top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word(word):\n",
    "    speech_list = []\n",
    "    \n",
    "    for x in data_dtmi.columns:\n",
    "        print(x)\n",
    "        print(data_dtmi.iloc[0])\n",
    "        break\n",
    "\n",
    "find_word(\"vore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_by_year(search_year, amount):\n",
    "    top_dict = {}\n",
    "    data = data_dtm.transpose()\n",
    "    for x in data.columns:\n",
    "        if search_year == int(x):\n",
    "            top = data[x].sort_values(ascending=False).head(amount)\n",
    "            top_dict[x] = list(zip(top.index, top.values))\n",
    "            break\n",
    "\n",
    "    return top_dict\n",
    "\n",
    "#print(top_words_by_year(2005,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge wordcloud (run once)\n",
    "from wordcloud import WordCloud\n",
    "wc = WordCloud (stopwords=sw_dk, background_color=\"white\", colormap=\"Dark2\", \n",
    "max_font_size=150, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_wordcloud_all():\n",
    "    plt.rcParams['figure.figsize'] = [16,6]\n",
    "\n",
    "    all_years = get_years()\n",
    "\n",
    "    for i, x in enumerate(data_dict.values()):\n",
    "        wc.generate(x)\n",
    "  \n",
    "\n",
    "        plt.subplot(4, 5, i+1)\n",
    "        plt.imshow(wc, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"nytårstalen \" + str(all_years[i]))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "create_wordcloud_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(year):\n",
    "    plt.rcParams['figure.figsize'] = [16,6]\n",
    "    \n",
    "    text = data_dict[str(year)]\n",
    "    wc.generate(text)\n",
    "    \n",
    "    plt.subplot()\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"nytårstalen \" + str(year))\n",
    "            \n",
    "create_wordcloud(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import arlstem2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_list = []\n",
    "\n",
    "for speech in data_dict.values():\n",
    "    print(speech)\n",
    "    #data_dtmi[year].nonzero()[0].size\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
